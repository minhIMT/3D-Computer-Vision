{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import time\n",
    "import PIL.Image as pil\n",
    "import numpy as np\n",
    "\n",
    "import mxnet as mx\n",
    "from mxnet.gluon.data.vision import transforms\n",
    "\n",
    "import gluoncv\n",
    "from gluoncv.model_zoo.monodepthv2.layers import disp_to_depth\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "import cv2\n",
    "\n",
    "# using cpu\n",
    "ctx = mx.cpu(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"D:/Computer Vision/3D computer vision/3D-Computer-Vision/Practice/2011_09_26_drive_0095_sync/2011_09_26/2011_09_26_drive_0095_sync/image_02/data\"\n",
    "\n",
    "files = os.listdir(data_path)\n",
    "files.sort()\n",
    "\n",
    "raw_img_sequences = []\n",
    "for file in files:\n",
    "    file = os.path.join(data_path, file)\n",
    "    img = pil.open(file).convert('RGB')\n",
    "    raw_img_sequences.append(img)\n",
    "\n",
    "original_width, original_height = raw_img_sequences[0].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_zoo = 'monodepth2_resnet18_kitti_stereo_640x192'\n",
    "model = gluoncv.model_zoo.get_model(model_zoo, pretrained_base=False, ctx=ctx, pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_depth = 0.1\n",
    "max_depth = 100\n",
    "\n",
    "# while use stereo or mono+stereo model, we could get real depth value\n",
    "scale_factor = 5.4\n",
    "MIN_DEPTH = 1e-3\n",
    "MAX_DEPTH = 80\n",
    "\n",
    "feed_height = 192\n",
    "feed_width = 640\n",
    "\n",
    "pred_depth_sequences = []\n",
    "pred_disp_sequences = []\n",
    "for img in raw_img_sequences:\n",
    "    img = img.resize((feed_width, feed_height), pil.LANCZOS)\n",
    "    img = transforms.ToTensor()(mx.nd.array(img)).expand_dims(0).as_in_context(context=ctx)\n",
    "\n",
    "    outputs = model.predict(img)\n",
    "    mx.nd.waitall()\n",
    "    pred_disp, _ = disp_to_depth(outputs[(\"disp\", 0)], min_depth, max_depth)\n",
    "    t = time.time()\n",
    "    pred_disp = pred_disp.squeeze().as_in_context(mx.cpu()).asnumpy()\n",
    "    pred_disp = cv2.resize(src=pred_disp, dsize=(original_width, original_height))\n",
    "    pred_disp_sequences.append(pred_disp)\n",
    "\n",
    "    pred_depth = 1 / pred_disp\n",
    "    pred_depth *= scale_factor\n",
    "    pred_depth[pred_depth < MIN_DEPTH] = MIN_DEPTH\n",
    "    pred_depth[pred_depth > MAX_DEPTH] = MAX_DEPTH\n",
    "    pred_depth_sequences.append(pred_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = os.path.join(os.path.expanduser(\".\"), \"tmp\")\n",
    "\n",
    "pred_path = os.path.join(output_path, 'pred')\n",
    "if not os.path.exists(pred_path):\n",
    "    os.makedirs(pred_path)\n",
    "\n",
    "for pred, file in zip(pred_depth_sequences, files):\n",
    "    pred_out_file = os.path.join(pred_path, file)\n",
    "    cv2.imwrite(pred_out_file, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_path = os.path.join(output_path, 'rgb')\n",
    "if not os.path.exists(rgb_path):\n",
    "    os.makedirs(rgb_path)\n",
    "\n",
    "output_sequences = []\n",
    "for raw_img, pred, file in zip(raw_img_sequences, pred_disp_sequences, files):\n",
    "    vmax = np.percentile(pred, 95)\n",
    "    normalizer = mpl.colors.Normalize(vmin=pred.min(), vmax=vmax)\n",
    "    mapper = cm.ScalarMappable(norm=normalizer, cmap='magma')\n",
    "    colormapped_im = (mapper.to_rgba(pred)[:, :, :3] * 255).astype(np.uint8)\n",
    "    im = pil.fromarray(colormapped_im)\n",
    "\n",
    "    raw_img = np.array(raw_img)\n",
    "    pred = np.array(im)\n",
    "    output = np.concatenate((raw_img, pred), axis=0)\n",
    "    output_sequences.append(output)\n",
    "\n",
    "    pred_out_file = os.path.join(rgb_path, file)\n",
    "    cv2.imwrite(pred_out_file, cv2.cvtColor(pred, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "width = int(output_sequences[0].shape[1] + 0.5)\n",
    "height = int(output_sequences[0].shape[0] + 0.5)\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter(\n",
    "    os.path.join(output_path, 'demo.mp4'), fourcc, 20.0, (width, height))\n",
    "\n",
    "for frame in output_sequences:\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    out.write(frame)\n",
    "    cv2.imshow('demo', frame)\n",
    "\n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
